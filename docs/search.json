[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 262 Notes",
    "section": "",
    "text": "Course Goals for STAT 262\nSTAT 262 is an introduction to formal statistical inference. We will carry out inference using both simulation-based approaches and classical, theory-based methods. By the end of the course, you will:",
    "crumbs": [
      "Course Goals for STAT 262"
    ]
  },
  {
    "objectID": "Section 1 Probability.html",
    "href": "Section 1 Probability.html",
    "title": "1  Philosophy of Statistical Inference (Chapters 11-14)",
    "section": "",
    "text": "1.1 Randomization Tests (Chapter 11)\nIn STAT 101, you focused on Exploratory Data Analysis. Exploratory data analysis aims to investigate the characteristics of a data set through visualizations and numerical summaries. Visualizations may include:\nNumerical summaries used to explore a data set may include:\nMore often than not, the data were collected to answer a research question about a larger population for which the data collected are a (hopefully) representative sample. This notion of drawing conclusions beyond the data collected is at the heart of statistical inference.\nExample: Bred in the Bone\nTake away:\nIn exploratory data analysis, the visualizations and numerical summaries you choose are driven by the type of data at hand. This is true for statistical inference as well. The type of data will drive the appropriate inference techniques. However, the goal of the research study will also impact the selected method, as will the underlying assumptions of the technique (we’ll talk a lot more about this). That said, there are some overarching approaches to quantifying variability, and thus drawing conclusions beyond the data set at hand.\nApproaches to quantifying variability\nWe’ll start the semester by talking about these three approaches fairly generally. For (most of) the rest of the semester, we’ll see how these approaches fit with different types of data.\nThe goal of hypothesis tests is to use an observed data set to answer a yes/no question about a characteristic of a larger population from which the observed data set was drawn. For example, is swimming with dolphins therapeutic for patients with clinical depression? That is, we want to assess whether or not the explanatory variable causes changes in the response variable.\nTo answer this question, Antonioli and Reveley (2005) recruited 30 subjects with a clinical diagnosis of mild to moderate depression. The subjects were required to stop all other treatments (therapy and/or pharmaceuticals) 4 weeks prior the experiment, and the 30 subjects were all taken to an island off the coast of Honduras. The subjects were randomly assigned to one of two groups. Both groups spent one hour swimming and snorkeling each day, but one group did so in the presence of dolphins and the other group did not. At the end of two weeks, each subject’s level of depressions was evaluated, and whether or not the subjects had a substantial improvement in their depression was recorded.\nExplanatory variable:\nResponse variable:\nIs this an observational study or an experiment? What does that imply about inference?\nThe question we will answer is whether the resulting data provide convincing evidence that subjects who swam with dolphins were more likely to see depression improvement than subjects who swam without dolphins.\nIf there really is no impact of swimming with dolphins, what does this imply about the explanatory and response variables?\nIf swimming with dolphins does improve depression, what does this imply about the explanatory and response variables?\nThis leads to two competing claims:\nIf the null hypothesis is true, how would this manifest in the observed data?\nIf the alternative hypothesis is true, how would this manifest in the observed data?\nWe will choose between the competing claims by assessing whether the data conflict so much with H\\(_0\\) that the null hypothesis cannot be considered reasonable. If this happens, we’ll reject the notion of H\\(_0\\) and conclude that H\\(_a\\) must be true.\nUp to now, we haven’t seen the data! Here’s a summary:\nWe can see that\nSo,\nThe question remains…is this enough different from what we would expect under the null hypothesis to conclude that swimming with dolphins does make a difference in depression?\nSo far, nothing we’ve laid out is unique to a randomization test. Where does randomization come in?\nLet’s visualize these observations as a set of cards. Each card denotes a subject in the study. The color indicates the response: red for substantial improvement and black for no substantial improvement.\nAny difference we see in the simulation is due to chance–the cards were randomly dealt into the dolphin/control groups.\nIt’s not realistic to keep shuffling and dealing by hand…we need to turn to technology to do the randomization for us: Applet\nWe can do this over and over again to build up a null distribution. This distribution shows how we expect the variability to behave under the null hypothesis:\nWhat do you notice about this null distribution?\nHow rare is it to see our observed statistic 0.467 in this distribution? What does this imply?\nSo, we’ve just carried out a statistical inference technique! We might be wrong in our conclusions (more on this in Chapter 14), but we’ve made the best decision we could with the data available.\nIn summary:\nRandomization Test Procedure:\nNow let’s go to R!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Philosophy of Statistical Inference (Chapters 11-14)</span>"
    ]
  },
  {
    "objectID": "Section 1 Probability.html#randomization-tests-chapter-11",
    "href": "Section 1 Probability.html#randomization-tests-chapter-11",
    "title": "1  Philosophy of Statistical Inference (Chapters 11-14)",
    "section": "",
    "text": "Null hypothesis: H\\(_0\\)\n\n\n\nAlternative hypothesis: H\\(_a\\)\n\n\n\n\n\n\n\n\n\n\n\n\nDolphin Therapy\nControl Group\nTotal\n\n\n\n\nShowed Improvement\n\n\n\n\n\nNo Improvement\n\n\n\n\n\nTotal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrame the research question in terms of hypotheses\nCollect data from an observational study or experiment\nModel randomness that would occur if H\\(_0\\) is true\nAnalyze the data by comparing the observed data to the simulated distribution\nConclusion",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Philosophy of Statistical Inference (Chapters 11-14)</span>"
    ]
  },
  {
    "objectID": "Section 1 Probability.html#bootstrap-methods-chapter-12",
    "href": "Section 1 Probability.html#bootstrap-methods-chapter-12",
    "title": "1  Philosophy of Statistical Inference (Chapters 11-14)",
    "section": "1.2 Bootstrap Methods (Chapter 12)",
    "text": "1.2 Bootstrap Methods (Chapter 12)\nBootstrap methods are a relatively new statistical technique (proposed in 1979 by Efron), but they are based on a very simple idea. The goal is to characterize the variability of the statistic across many samples. One way we could do this is take lots and lots of samples from the population, and get a picture of how much variance there is among the samples. This is almost always impossible. So, rather than resample from the population, we could try resampling from the sample. This is the basic idea behind the bootstrap.\nBootstrapping is used in many different applications. For this general introduction to the approach, we’re going to consider a confidence interval for a proportion.\nA confidence interval is\n\n\n\n\n\nNote the goal of the confidence interval is different from the goal of a hypothesis test!\n\n\n\n\nHowever, like with hypothesis tests, we need to understand the variability inherent to the statistic. To figure out how wide the range of plausible values should be, we need to know how a statistic varies from sample to sample in the population.\nFor example, let’s think back to the Baby scenario and suppose our goal is to estimate the population parameter\n\n\n\n\nThe researchers collected one sample of 16 babies, and found that 14 picked the good guy. This is our observed data. What do you think would happen if we took a sample of 16 different babies? And then a different sample of 16 babies?\n\n\n\n\nIdea of the bootstrap:\n\n\n\n\n\n\n\nInfinite populations are pretty tough to work with, though. However, we can produce an equivalent bootstrap distribution by\n\n\n\n\nSo, we’ll repeatedly draw bootstrap samples of size 16 (why 16?) and calculate the proportion of successes in each bootstrap samples. After we do this many many times, we’ll have an idea of a range of plausible values for the population parameter. We’ll set the confidence level by opting for a wider or a narrower interval, based on how certain we need to be in the results.\n\n\n\n\nBootstrap Process\n\nFrame the research question in terms of a parameter to estimate\nCollect data using an observational study or an experiment\nModel the randomness by using the observed data as a proxy for the population\nCreate the interval (in future chapters we’ll see there are multiple ways to do this)\nConclusion\n\nLet’s go to R!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Philosophy of Statistical Inference (Chapters 11-14)</span>"
    ]
  },
  {
    "objectID": "Section 1 Probability.html#inference-with-mathematical-models-chapter-13",
    "href": "Section 1 Probability.html#inference-with-mathematical-models-chapter-13",
    "title": "1  Philosophy of Statistical Inference (Chapters 11-14)",
    "section": "1.3 Inference with Mathematical Models (Chapter 13)",
    "text": "1.3 Inference with Mathematical Models (Chapter 13)\nSo far, we’ve seen computational methods like randomization and bootstrapping to characterize the variability of a statistic. The use of computational methods is relatively recent, due to the increase in computing power. In pre-computing days, re-sampling and randomization was very difficult. As a result, mathematical approximations were used and are still pervasive. If you took AP Statistics or a different intro statistics course, you employed mathematical models. However, to be clear, all of the methods we’ll talk about (randomization, bootstrap, mathematical models) are techniques to get a sampling distribution.\n\n\n\n\n\n\n\n\nThe sampling distributions we’ve seen so far have been (mostly):\n\n\n\n\n\n\nThis isn’t coincidence…it’s guaranteed by a very important theorem, the Central Limit Theorem.\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\n\n\n\n\nWhat are the requirements here?\n\nIndependence:\n\n\n\n\n“Large enough”:\n\n\n\n\n\nNormal Distribution: Nothing followings it exactly–it’s a mathematical construct. But, a lot of things follow it approximately, either:\n\nnaturally:\n\n\n\ncreated to follow it:\n\n\n\nThe normal distribution depends on two parameters, \\(\\mu=\\) mean (where the distribution is centered) and \\(\\sigma=\\) standard deviation (how spread out it is). \\(\\mu\\) shifts the distribution up and down the number line, \\(\\sigma\\) stretches and contracts the curve. The standard normal distribution has \\(\\mu=0\\) and \\(\\sigma=1\\) (this is the distribution tabulated in normal tables in textbooks).\nThe standard normal gives us a convenient way to compare observations, and any normal distribution can be transformed into a standard normal. The Z-score is\n\n\n\n\nIf the Z-score is positive\n\n\nIf the Z-score is negative\nZ-scores can be used to\n\ngauge the unusualness of an observation\n\n\n\nfind probabilities\n\n\n\n\n\nHelpful R functions:\n\npnorm(x, mean=0, sd=1)\nnormTail(m=0,s=1,L=x) or normTail(m=0,s=1,U=x) will draw pretty pictures–need to use the OpenIntro library\nqnorm(prob, mean=0, sd=1) gives a Z-score with area to the left\n\nPictures are super-helpful!\nExample: Full-term birth weights for single babies are normally distributed with a mean of 7.5 pounds and a standard deviation of 1.1 pounds.\n\nA baby is born weighing 9.1 pounds. What is the weight percentile for this baby?\n\n\n\n\n\n\nBabies that weigh less than 5.5 pounds are considered low birth weight. What proportion of babies are low birth weight?\n\n\n\n\n\n\nWhat weight would make a baby at the 25th percentile?\n\n\nWhat is the probability a randomly selected baby weighs between 7 and 8 pounds?\n\n\n\n\n\n\n\n\n\nThe Empirical Rule (aka the 68-95-99.7 Rule) presents a general rule for the probability of falling within one, two, and three standard deviations of the mean in a normal distribution.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis rule is useful in a wide range of settings when trying to make quick estimate (we’ll use it with bootstraps too!).\nSome more definitions we’ll use throughout the semester:\n\nStandard error:\n\n\n\n\n\n\n\nMargin of error:\n\n\n\n\n\n\nExample (13.11): In 2013, the Pew Research Foundation reported that “45% of US adults report that they live with one ore more chronic conditions.” However, this value was based on a sample, so it may not be a perfect estimate for the population parameter of interest on its own. The study reported a standard error of about 1.2%, and a normal model may reasonably be used. Create a 95% confidence interval for the proportion of US adults who live with one or more chronic conditions. Interpret the confidence interval in the context of the study.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Philosophy of Statistical Inference (Chapters 11-14)</span>"
    ]
  },
  {
    "objectID": "Section 1 Probability.html#decision-errors-chapter-14",
    "href": "Section 1 Probability.html#decision-errors-chapter-14",
    "title": "1  Philosophy of Statistical Inference (Chapters 11-14)",
    "section": "1.4 Decision Errors (Chapter 14)",
    "text": "1.4 Decision Errors (Chapter 14)\nAnytime we’re using sample data to make decisions about a larger population we can potentially make a mistake. We can make an incorrect decision in a hypothesis test or calculate a confidence interval that does not capture the true population parameter. In a hypothesis test, there are four possible outcomes:\n\n\n\n\n\n\n\n\n\n\nType I error:\n\n\n\nType II error:\nExamples:\n\nDoping in the Olympics\n\n\n\n\n\n\n\n\n\nCriminal trial\n\n\n\n\n\n\n\n\n\nDiagnostic test for a serious disease\n\n\n\n\n\n\n\n\nErrors require a balancing act. We want to reduce the chance of making a Type I error but this will necessarily increase the chance of making a Type II error. The best we can do is to set the probability of a Type I error. We can do through setting the significance level.\nSignificance level:\n\n\n\n\n\n\nAnother consideration that will impact the chance of making an error is the whether the test is one- or two-sided.\nTwo-sided hypotheses:\n\n\n\n\n\n\nExample: Standard anticoagulant therapy to prevent blood clots requires frequent (expensive) lab monitoring. A new procedure called riva was tested because it did not require frequent monitoring. A randomized trial was conducted in 2012, with standard therapy randomly assigned to 2416 patients and riva randomly assigned to 2416 patients. A bad result was a recurrence of a blood clot in a vein. We want to know if the likelihood of a bad result is different between the two therapies.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere are the results of the randomized trial\n\n\n\n\nRiva\nStandard\nTotal\n\n\n\n\nClot\n44\n60\n104\n\n\nNo Clot\n2372\n2356\n4728\n\n\nTotal\n2416\n2416\n4832\n\n\n\n\n\n\n\nFor two-sided tests, the p-value is the probability that we observe a result as least as favorable to the alternative hypothesis as the result we observe. That is, that we observe a result as extreme or more extreme in either direction.\n\n\n\n\n\n\nWhen in doubt, use a two-sided test! Use a one-sided test only if you truly have interest in only one direction.\nSo, how can we control Type I error?\n\nSet up tests before seeing the data.\nCollect enough data that the test has sufficient power. We’ll talk more about power later (and LOTS more in an experimental design course), but power is the probability of correctly rejecting a false null hypothesis. It’s a function of how big the true difference is (which we don’t know and can’t control) and the sample size (which we can control).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Philosophy of Statistical Inference (Chapters 11-14)</span>"
    ]
  }
]